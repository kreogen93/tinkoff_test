{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62a37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c578a11",
   "metadata": {},
   "source": [
    "## Знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "751d1a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>release</th>\n",
       "      <th>n_0000</th>\n",
       "      <th>n_0001</th>\n",
       "      <th>n_0002</th>\n",
       "      <th>n_0003</th>\n",
       "      <th>n_0004</th>\n",
       "      <th>n_0005</th>\n",
       "      <th>n_0006</th>\n",
       "      <th>n_0007</th>\n",
       "      <th>...</th>\n",
       "      <th>c_1368</th>\n",
       "      <th>c_1369</th>\n",
       "      <th>c_1370</th>\n",
       "      <th>c_1371</th>\n",
       "      <th>c_1372</th>\n",
       "      <th>c_1373</th>\n",
       "      <th>c_1374</th>\n",
       "      <th>c_1375</th>\n",
       "      <th>c_1376</th>\n",
       "      <th>c_1377</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11193</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11382</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16531</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18262</td>\n",
       "      <td>c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id release  n_0000  n_0001    n_0002  n_0003  n_0004    n_0005  n_0006  \\\n",
       "0  11193       a     NaN     NaN  0.025449     NaN     NaN  0.368421     NaN   \n",
       "1  11382       a     NaN     NaN  0.031297     NaN     NaN  0.315789     NaN   \n",
       "2  16531       a     NaN     NaN  0.024475     NaN     NaN  0.342105     NaN   \n",
       "3   1896       a     NaN     NaN  0.041694     NaN     NaN  0.447368     NaN   \n",
       "4  18262       c     NaN     NaN  0.038120     NaN     NaN  0.315789     NaN   \n",
       "\n",
       "   n_0007  ...  c_1368  c_1369  c_1370  c_1371  c_1372  c_1373  c_1374  \\\n",
       "0     NaN  ...     NaN     NaN     NaN     NaN       a     NaN       q   \n",
       "1     NaN  ...     NaN     NaN       a     NaN       a     NaN     NaN   \n",
       "2     NaN  ...     NaN     NaN       a     NaN       a     NaN       b   \n",
       "3     NaN  ...     NaN     NaN     NaN     NaN       a     NaN     NaN   \n",
       "4     NaN  ...     NaN     NaN       b     NaN       a     NaN       a   \n",
       "\n",
       "   c_1375  c_1376  c_1377  \n",
       "0     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN  \n",
       "3     NaN     NaN     NaN  \n",
       "4     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 1379 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ds_problem/problem_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede7b5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>service_a</th>\n",
       "      <th>service_b</th>\n",
       "      <th>service_c</th>\n",
       "      <th>service_d</th>\n",
       "      <th>service_e</th>\n",
       "      <th>service_f</th>\n",
       "      <th>service_g</th>\n",
       "      <th>service_h</th>\n",
       "      <th>service_i</th>\n",
       "      <th>service_j</th>\n",
       "      <th>service_k</th>\n",
       "      <th>service_l</th>\n",
       "      <th>service_m</th>\n",
       "      <th>service_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  service_a  service_b  service_c  service_d  service_e  service_f  \\\n",
       "0  11193          1          1          0          0          0          0   \n",
       "1  11382          0          0          0          0          0          0   \n",
       "2  16531          0          0          0          0          0          0   \n",
       "3   1896          0          0          0          1          0          0   \n",
       "4  18262          0          0          0          1          1          0   \n",
       "\n",
       "   service_g  service_h  service_i  service_j  service_k  service_l  \\\n",
       "0          0          0          0          1          1          0   \n",
       "1          0          0          0          1          1          0   \n",
       "2          0          0          0          1          1          0   \n",
       "3          0          0          0          1          0          1   \n",
       "4          0          0          0          0          1          1   \n",
       "\n",
       "   service_m  service_n  \n",
       "0          0          0  \n",
       "1          0          0  \n",
       "2          0          0  \n",
       "3          0          0  \n",
       "4          1          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.read_csv('ds_problem/problem_labels.csv')\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7580ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Absolute Correlations\n",
      "service_l  service_m    0.804081\n",
      "service_a  service_b    0.557859\n",
      "service_j  service_k    0.533591\n",
      "service_d  service_e    0.418327\n",
      "service_b  service_c    0.405167\n",
      "service_f  service_g    0.395226\n",
      "service_a  service_c    0.330330\n",
      "service_h  service_l    0.308826\n",
      "service_c  service_g    0.267283\n",
      "service_h  service_m    0.213137\n",
      "service_c  service_e    0.182957\n",
      "service_h  service_n    0.178128\n",
      "service_d  service_m    0.173341\n",
      "service_e  service_m    0.172998\n",
      "service_h  service_i    0.170898\n",
      "service_e  service_l    0.166700\n",
      "service_d  service_l    0.150511\n",
      "service_c  service_m    0.137605\n",
      "service_b  service_g    0.135366\n",
      "service_c  service_h    0.134676\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(df_target.drop('id', axis=1), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca728324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service_a 0.472125\n",
      "service_b 0.32825\n",
      "service_c 0.261625\n",
      "service_d 0.017\n",
      "service_e 0.053875\n",
      "service_f 0.029125\n",
      "service_g 0.051875\n",
      "service_h 0.297\n",
      "service_i 0.016125\n",
      "service_j 0.84825\n",
      "service_k 0.782\n",
      "service_l 0.108\n",
      "service_m 0.088625\n",
      "service_n 0.178\n"
     ]
    }
   ],
   "source": [
    "#Посмотрим на балансы классов\n",
    "for col in df_target.drop('id', axis=1).columns:\n",
    "    print(col, df_target[col].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f19c666",
   "metadata": {},
   "source": [
    "## обработка пустых значений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9021f1",
   "metadata": {},
   "source": [
    "Разделим выборку на треин и тест. Обучим бейзлайновую модель с заполнением пропусков константой  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9d9ccf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitiing_base_model(df, df_target):\n",
    "    for col in df_target.drop('id', axis=1).columns:\n",
    "        df_train, df_test = train_test_split(\n",
    "            df,\n",
    "            test_size=0.25,\n",
    "            stratify=df_target[col]\n",
    "        )\n",
    "        model = CatBoostClassifier(iterations=50)\n",
    "        train = df_train.merge(df_target[['id', col]], on='id', how='inner')\n",
    "        X, y = train.drop([col, 'id'], axis=1), train[col]\n",
    "        model.fit(X, y, verbose=False)\n",
    "        scores_train.append(log_loss(y, model.predict_proba(X)[:, 1]))\n",
    "        test = df_test.merge(df_target[['id', col]], on='id', how='inner')\n",
    "        X, y = test.drop([col, 'id'], axis=1), test[col]\n",
    "        scores_test.append(log_loss(y, model.predict_proba(X)[:, 1]))\n",
    "    return (np.mean(scores_train), np.mean(scores_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40298b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "scores_train = []\n",
    "scores_test = []\n",
    "cat_features = [col for col in df.columns if df[col].dtype == np.object]\n",
    "df_const = df.fillna(-1)\n",
    "\n",
    "train_score, test_score = fitiing_base_model(df_const, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7681fd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество на треине 3.03779590963289\n",
      "Среднее качество на тесте 3.9781649620487136\n"
     ]
    }
   ],
   "source": [
    "print('Среднее качество на треине', train_score)\n",
    "print('Среднее качество на тесте', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5dc7a",
   "metadata": {},
   "source": [
    "Проведем эксперименты с колонками, у которых разреженность не более 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33e34a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 608)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clear = df.copy()\n",
    "for col in df.columns:\n",
    "    if df_clear[col].isna().sum() / df_clear.shape[0] >= 0.95:\n",
    "        df_clear = df_clear.drop(col, axis=1)\n",
    "df_clear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f3966b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [col for col in df_clear.columns if df_clear[col].dtype == np.object]\n",
    "for col in cat_features:\n",
    "    if df_clear[col].value_counts().shape[0] < 2:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d685b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удалим колонку с единственным уникальным значением\n",
    "df_clear = df_clear.drop('c_1078', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "79090642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install category_encoders\n",
    "import category_encoders as ce\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def target_encode(df, col, y):\n",
    "    class_names=y.columns\n",
    "    \n",
    "    clasters = pd.DataFrame()\n",
    "    for class_ in class_names:\n",
    "        enc=ce.TargetEncoder()\n",
    "        enc.fit(df[col], y[class_])\n",
    "        \n",
    "        temp=enc.transform(df[col])\n",
    "        clasters = pd.concat([clasters, temp], axis=1)\n",
    "    clasters = clasters.to_numpy()\n",
    "    pca = PCA(n_components=4)\n",
    "    pca_decomp = pd.DataFrame(pca.fit_transform(clasters), columns = [col + str(i) for i in range(4)])\n",
    "    df = df.drop(col, axis=1)\n",
    "    df=pd.concat([df, pca_decomp], axis=1)    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610417c",
   "metadata": {},
   "source": [
    "Будем обрабатывать категориальные значения по следующему правилу: если не более 4 уникальных значений, то буду делать заполнение пропусков модой и затем One-Hot-Encoding, иначе буду обрабатывать Target-Encoding с заполнением пропусков модой, если разреженность столбца не более 0.7, иначе будем воспринимать пропуск как отдельную категорию. Здесь можно провести очень много разных экспериментов. Но попытаемся по логике принять на веру, что это лучший вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c628191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_features:\n",
    "    if df_clear[col].value_counts().shape[0] <= 4:\n",
    "        df_clear[col] = df_clear[col].fillna(df_clear[col].value_counts().index[0])\n",
    "        one_hot = pd.get_dummies(df_clear[col], prefix=col, drop_first=True)\n",
    "        df_clear = pd.concat((df_clear.drop(col, axis=1), one_hot), axis=1)\n",
    "    else:\n",
    "        if df_clear[col].isna().sum() / df_clear.shape[0] <= 0.7:\n",
    "            df_clear[col] = df_clear[col].fillna(df_clear[col].value_counts().index[0])\n",
    "        df_clear = target_encode(df_clear, col, df_target)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90f0e485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_0002</th>\n",
       "      <th>n_0005</th>\n",
       "      <th>n_0006</th>\n",
       "      <th>n_0007</th>\n",
       "      <th>n_0012</th>\n",
       "      <th>n_0015</th>\n",
       "      <th>n_0017</th>\n",
       "      <th>n_0019</th>\n",
       "      <th>n_0020</th>\n",
       "      <th>...</th>\n",
       "      <th>c_13733</th>\n",
       "      <th>c_13740</th>\n",
       "      <th>c_13741</th>\n",
       "      <th>c_13742</th>\n",
       "      <th>c_13743</th>\n",
       "      <th>c_13750</th>\n",
       "      <th>c_13751</th>\n",
       "      <th>c_13752</th>\n",
       "      <th>c_13753</th>\n",
       "      <th>c_1377_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11193</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>-79.368513</td>\n",
       "      <td>-0.283316</td>\n",
       "      <td>0.062843</td>\n",
       "      <td>-0.034096</td>\n",
       "      <td>10.550475</td>\n",
       "      <td>-0.017823</td>\n",
       "      <td>-0.005955</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11382</td>\n",
       "      <td>0.031297</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>6.001752</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>-0.021504</td>\n",
       "      <td>-0.003797</td>\n",
       "      <td>10.550475</td>\n",
       "      <td>-0.017823</td>\n",
       "      <td>-0.005955</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16531</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>6.001752</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>-0.021504</td>\n",
       "      <td>-0.003797</td>\n",
       "      <td>10.550475</td>\n",
       "      <td>-0.017823</td>\n",
       "      <td>-0.005955</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>6.001752</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>-0.021504</td>\n",
       "      <td>-0.003797</td>\n",
       "      <td>10.550475</td>\n",
       "      <td>-0.017823</td>\n",
       "      <td>-0.005955</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18262</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>-254.647679</td>\n",
       "      <td>0.083493</td>\n",
       "      <td>0.043634</td>\n",
       "      <td>0.163128</td>\n",
       "      <td>10.550475</td>\n",
       "      <td>-0.017823</td>\n",
       "      <td>-0.005955</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    n_0002    n_0005  n_0006  n_0007    n_0012  n_0015    n_0017  \\\n",
       "0  11193  0.025449  0.368421     NaN     NaN  0.292683     NaN       NaN   \n",
       "1  11382  0.031297  0.315789     NaN     NaN  0.243902     NaN       NaN   \n",
       "2  16531  0.024475  0.342105     NaN     NaN  0.304878     NaN       NaN   \n",
       "3   1896  0.041694  0.447368     NaN     NaN  0.207317     NaN       NaN   \n",
       "4  18262  0.038120  0.315789     NaN     NaN  0.219512     NaN  0.388889   \n",
       "\n",
       "   n_0019  n_0020  ...   c_13733     c_13740   c_13741   c_13742   c_13743  \\\n",
       "0     0.0     NaN  ...  0.001262  -79.368513 -0.283316  0.062843 -0.034096   \n",
       "1     0.0     NaN  ...  0.001262    6.001752  0.041844 -0.021504 -0.003797   \n",
       "2     0.0     NaN  ...  0.001262    6.001752  0.041844 -0.021504 -0.003797   \n",
       "3     0.0     NaN  ...  0.001262    6.001752  0.041844 -0.021504 -0.003797   \n",
       "4     0.0     NaN  ...  0.001262 -254.647679  0.083493  0.043634  0.163128   \n",
       "\n",
       "     c_13750   c_13751   c_13752   c_13753  c_1377_b  \n",
       "0  10.550475 -0.017823 -0.005955  0.000347         1  \n",
       "1  10.550475 -0.017823 -0.005955  0.000347         1  \n",
       "2  10.550475 -0.017823 -0.005955  0.000347         1  \n",
       "3  10.550475 -0.017823 -0.005955  0.000347         1  \n",
       "4  10.550475 -0.017823 -0.005955  0.000347         1  \n",
       "\n",
       "[5 rows x 1249 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7ff28",
   "metadata": {},
   "source": [
    "Заполнение средним значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d4a0882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med = df_clear.copy()\n",
    "for col in df_med.drop('id', axis=1).columns:\n",
    "    df_med[col] = df_med[col].fillna(df_med[col].mean())\n",
    "    \n",
    "train_score, test_score = fitiing_base_model(df_med, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d9ee9780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество на треине 0.18256156338297375\n",
      "Среднее качество на тесте 0.2844665406058263\n"
     ]
    }
   ],
   "source": [
    "print('Среднее качество на треине', train_score)\n",
    "print('Среднее качество на тесте', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b1cf1e",
   "metadata": {},
   "source": [
    "Заполнение при помощи линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4ee1659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def linreg_imputer(df):\n",
    "    for col in df.drop('id', axis=1).columns:\n",
    " \n",
    "        if df[col].isna().sum() == 0:\n",
    "            continue\n",
    "        # обучающей выборкой будут строки без пропусков\n",
    "        train = df.dropna().copy()\n",
    "        # тестовой (или вернее выборкой для заполнения пропусков)\n",
    "        # будут те строки, в которых пропуски есть\n",
    "        test = df[df[col].isnull()].copy()\n",
    "\n",
    "        # выясним индекс столбца с пропусками\n",
    "        col_index = df.columns.get_loc(col)\n",
    "\n",
    "        # разделим \"целевую переменную\" и \"признаки\"\n",
    "        # обучающей выборки\n",
    "        y_train = train[col]\n",
    "        X_train = train.drop(col, axis = 1)\n",
    "\n",
    "        # из тестовой выборки удалим столбец с пропусками\n",
    "        test = test.drop(col, axis = 1)\n",
    "\n",
    "        # обучим модель линейной регрессии\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # сделаем прогноз пропусков\n",
    "        y_pred = model.predict(test)\n",
    "        # вставим пропуски (value) на изначальное место (loc) столбца с пропусками (column)\n",
    "        test.insert(loc = col_index, column = col, value = y_pred)\n",
    "\n",
    "        # соединим датасеты и обновим индекс\n",
    "        df = pd.concat([train, test])\n",
    "        df.sort_index(inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = linreg_imputer(df_clear)\n",
    "\n",
    "train_score, test_score = fitiing_base_model(df_reg, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a1d89be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество на треине 0.49756156338291235\n",
      "Среднее качество на тесте 0.5675611234487564\n"
     ]
    }
   ],
   "source": [
    "print('Среднее качество на треине', train_score)\n",
    "print('Среднее качество на тесте', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd353a",
   "metadata": {},
   "source": [
    "Заполнение при помощи mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "lr = LinearRegression()\n",
    "imp = IterativeImputer(estimator=lr,missing_values=np.nan, max_iter=10, verbose=2, imputation_order='roman',random_state=0)\n",
    "df_mice = imp.fit_transform(df_clear)\n",
    "\n",
    "df_mice = pd.concat([df_clear['id'], df_mice.iloc], axis = 1)\n",
    "train_score, test_score = fitiing_base_model(df_mice, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Среднее качество на треине', train_score)\n",
    "print('Среднее качество на тесте', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0d294",
   "metadata": {},
   "source": [
    "Заполнение при помощи kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fab1c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "knn = KNNImputer(n_neighbors=5, add_indicator=True)\n",
    "\n",
    "df_knn = df_clear.copy()\n",
    "knn.fit(df_knn)\n",
    "knn.transform(df_knn)\n",
    "\n",
    "train_score, test_score = fitiing_base_model(df_knn, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d5e6503b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество на треине 1.2069765763965212\n",
      "Среднее качество на тесте 2.309854718524335\n"
     ]
    }
   ],
   "source": [
    "print('Среднее качество на треине', train_score)\n",
    "print('Среднее качество на тесте', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bdd684",
   "metadata": {},
   "source": [
    "Как вариант попробовать еще заполнение с помощью DataWig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0888482b",
   "metadata": {},
   "source": [
    "## Понижение признакового пространства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e7963df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Уберем квазиконстантные признаки\n",
    "#Для начала отмасштабируем данные\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_med.drop('id', axis=1))\n",
    "df_scaler = pd.DataFrame(scaler.transform(df_med.drop('id', axis=1)), columns = df_med.drop('id', axis=1).columns)\n",
    "df_scaler = pd.concat([df_med['id'], df_scaler], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0eb74cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_0047', 'n_0050', 'n_0052', 'n_0061', 'n_0075', 'n_0091']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_columns = []\n",
    "for col in df_scaler.columns:\n",
    "    if col != 'id' and df_scaler[col].var() < 1.0001:\n",
    "        del_columns.append(col)\n",
    "del_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d5ad851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med = df_med.drop(del_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bc9e35d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_0002</th>\n",
       "      <th>n_0005</th>\n",
       "      <th>n_0006</th>\n",
       "      <th>n_0007</th>\n",
       "      <th>n_0012</th>\n",
       "      <th>n_0015</th>\n",
       "      <th>n_0017</th>\n",
       "      <th>n_0019</th>\n",
       "      <th>n_0020</th>\n",
       "      <th>...</th>\n",
       "      <th>c_13730</th>\n",
       "      <th>c_13731</th>\n",
       "      <th>c_13732</th>\n",
       "      <th>c_13733</th>\n",
       "      <th>c_13740</th>\n",
       "      <th>c_13741</th>\n",
       "      <th>c_13742</th>\n",
       "      <th>c_13743</th>\n",
       "      <th>c_13750</th>\n",
       "      <th>c_1377_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11193</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.193175</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.036403</td>\n",
       "      <td>0.453657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447952</td>\n",
       "      <td>...</td>\n",
       "      <td>3.979702</td>\n",
       "      <td>-0.01044</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>-79.368513</td>\n",
       "      <td>-0.283316</td>\n",
       "      <td>0.062843</td>\n",
       "      <td>-0.034096</td>\n",
       "      <td>10.550475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11382</td>\n",
       "      <td>0.031297</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.193175</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.036403</td>\n",
       "      <td>0.453657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447952</td>\n",
       "      <td>...</td>\n",
       "      <td>3.979702</td>\n",
       "      <td>-0.01044</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>6.001752</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>-0.021504</td>\n",
       "      <td>-0.003797</td>\n",
       "      <td>10.550475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16531</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.193175</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.036403</td>\n",
       "      <td>0.453657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447952</td>\n",
       "      <td>...</td>\n",
       "      <td>3.979702</td>\n",
       "      <td>-0.01044</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>6.001752</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>-0.021504</td>\n",
       "      <td>-0.003797</td>\n",
       "      <td>10.550475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.193175</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.036403</td>\n",
       "      <td>0.453657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447952</td>\n",
       "      <td>...</td>\n",
       "      <td>3.979702</td>\n",
       "      <td>-0.01044</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>6.001752</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>-0.021504</td>\n",
       "      <td>-0.003797</td>\n",
       "      <td>10.550475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18262</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.193175</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.036403</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447952</td>\n",
       "      <td>...</td>\n",
       "      <td>3.979702</td>\n",
       "      <td>-0.01044</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>-254.647679</td>\n",
       "      <td>0.083493</td>\n",
       "      <td>0.043634</td>\n",
       "      <td>0.163128</td>\n",
       "      <td>10.550475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 939 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    n_0002    n_0005    n_0006    n_0007    n_0012    n_0015  \\\n",
       "0  11193  0.025449  0.368421  0.193175  0.012012  0.292683  0.036403   \n",
       "1  11382  0.031297  0.315789  0.193175  0.012012  0.243902  0.036403   \n",
       "2  16531  0.024475  0.342105  0.193175  0.012012  0.304878  0.036403   \n",
       "3   1896  0.041694  0.447368  0.193175  0.012012  0.207317  0.036403   \n",
       "4  18262  0.038120  0.315789  0.193175  0.012012  0.219512  0.036403   \n",
       "\n",
       "     n_0017  n_0019    n_0020  ...   c_13730  c_13731   c_13732   c_13733  \\\n",
       "0  0.453657     0.0  0.447952  ...  3.979702 -0.01044 -0.001815  0.001262   \n",
       "1  0.453657     0.0  0.447952  ...  3.979702 -0.01044 -0.001815  0.001262   \n",
       "2  0.453657     0.0  0.447952  ...  3.979702 -0.01044 -0.001815  0.001262   \n",
       "3  0.453657     0.0  0.447952  ...  3.979702 -0.01044 -0.001815  0.001262   \n",
       "4  0.388889     0.0  0.447952  ...  3.979702 -0.01044 -0.001815  0.001262   \n",
       "\n",
       "      c_13740   c_13741   c_13742   c_13743    c_13750  c_1377_b  \n",
       "0  -79.368513 -0.283316  0.062843 -0.034096  10.550475         1  \n",
       "1    6.001752  0.041844 -0.021504 -0.003797  10.550475         1  \n",
       "2    6.001752  0.041844 -0.021504 -0.003797  10.550475         1  \n",
       "3    6.001752  0.041844 -0.021504 -0.003797  10.550475         1  \n",
       "4 -254.647679  0.083493  0.043634  0.163128  10.550475         1  \n",
       "\n",
       "[5 rows x 939 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_med.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6151d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    del dataset[colname] # deleting the column from the dataset\n",
    "    \n",
    "correlation(df_med, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0b91c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Используем PCA\n",
    "train_score_arr, test_score_arr = {}, {}\n",
    "for n in range(300, 850, 50):\n",
    "    pca = PCA(n_components=n)\n",
    "\n",
    "    PCA_dataset = pca.fit_transform(df_med.drop('id', axis=1))\n",
    "    df_pca = pd.concat([df_med['id'], pd.DataFrame(PCA_dataset)], axis=1)\n",
    "    train_score, test_score = fitiing_base_model(df_pca, df_target)\n",
    "    train_score_arr[n] = train_score\n",
    "    test_score_arr[n] = test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5fec2156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество на треине 0.15109771887537293\n",
      "Среднее качество на тесте 0.33782779987993194\n"
     ]
    }
   ],
   "source": [
    "tr = 0\n",
    "mintest = float('inf')\n",
    "mintrain = 0\n",
    "for n in test_score_arr:\n",
    "    if mintest > test_score_arr[n]:\n",
    "        tr = n\n",
    "        mintest = test_score_arr[n]\n",
    "        mintrain = train_score_arr[n]\n",
    "\n",
    "print('Среднее качество на треине', mintrain)\n",
    "print('Среднее качество на тесте', mintest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e3b8fb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    }
   ],
   "source": [
    "print(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74446694",
   "metadata": {},
   "source": [
    "можно здесь же добавить понижение при помощи эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b2542ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "939"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим на количество столбцов\n",
    "df_med.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4b69ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Для начала преобразуем все входы в эмбеддинги 938 -> 36\n",
    "import torch\n",
    "\n",
    "\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "         \n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 938 ==> 36\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(938, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 36),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(36, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 938),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1b7622e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "model = AE()\n",
    " \n",
    "# Validation using MSE Loss function\n",
    "loss_function = torch.nn.MSELoss()\n",
    " \n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-1,\n",
    "                             weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d6e9a2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x228fedb6490>]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 20\n",
    "outputs = []\n",
    "losses = []\n",
    "data = torch.tensor(df_med.drop('id', axis=1).values).float()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "       \n",
    "      # Output of Autoencoder\n",
    "    reconstructed = model(data)\n",
    "\n",
    "    # Calculating the loss function\n",
    "    loss = loss_function(reconstructed, data)\n",
    "\n",
    "    # The gradients are set to zero,\n",
    "    # the gradient is computed and stored.\n",
    "    # .step() performs parameter update\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "      # Storing the losses in a list for plotting\n",
    "    losses.append(loss.detach().numpy())\n",
    "    outputs.append((epochs, data, reconstructed))\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(losses[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ec26ef7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    2322\n",
       "23    1821\n",
       "0      965\n",
       "10     944\n",
       "8      486\n",
       "9      404\n",
       "4      184\n",
       "31     173\n",
       "2      139\n",
       "14      98\n",
       "3       58\n",
       "13      56\n",
       "25      53\n",
       "27      45\n",
       "6       38\n",
       "22      32\n",
       "24      32\n",
       "7       29\n",
       "11      22\n",
       "28      16\n",
       "1       15\n",
       "30      14\n",
       "12      12\n",
       "19       8\n",
       "26       8\n",
       "20       7\n",
       "21       5\n",
       "18       4\n",
       "5        4\n",
       "16       2\n",
       "15       2\n",
       "29       2\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Попытаемся поделить данные на кластеры и для каждого кластера будем использовать расстояние до них как фичи\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=32, random_state=0).fit(df_med.drop('id', axis=1).values)\n",
    "df_cluster = df_med.copy()\n",
    "df_cluster['cluster'] = kmeans.labels_\n",
    "\n",
    "df_cluster['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "081fa59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_columns = ['distanceto' + str(i) for i in range(32)]\n",
    "dists_df = pd.DataFrame(\n",
    "    data=kmeans.transform(df_med.drop('id', axis=1).values),\n",
    "    columns=dists_columns\n",
    ")\n",
    "dists_df['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3879b9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distanceto0</th>\n",
       "      <th>distanceto1</th>\n",
       "      <th>distanceto2</th>\n",
       "      <th>distanceto3</th>\n",
       "      <th>distanceto4</th>\n",
       "      <th>distanceto5</th>\n",
       "      <th>distanceto6</th>\n",
       "      <th>distanceto7</th>\n",
       "      <th>distanceto8</th>\n",
       "      <th>distanceto9</th>\n",
       "      <th>...</th>\n",
       "      <th>distanceto23</th>\n",
       "      <th>distanceto24</th>\n",
       "      <th>distanceto25</th>\n",
       "      <th>distanceto26</th>\n",
       "      <th>distanceto27</th>\n",
       "      <th>distanceto28</th>\n",
       "      <th>distanceto29</th>\n",
       "      <th>distanceto30</th>\n",
       "      <th>distanceto31</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1158.757913</td>\n",
       "      <td>10308.004784</td>\n",
       "      <td>2184.890186</td>\n",
       "      <td>3570.769435</td>\n",
       "      <td>1764.062277</td>\n",
       "      <td>9178.431543</td>\n",
       "      <td>3627.118942</td>\n",
       "      <td>4014.283513</td>\n",
       "      <td>1053.936404</td>\n",
       "      <td>1398.246933</td>\n",
       "      <td>...</td>\n",
       "      <td>1064.633478</td>\n",
       "      <td>4828.255038</td>\n",
       "      <td>3091.622483</td>\n",
       "      <td>4353.631974</td>\n",
       "      <td>2134.944351</td>\n",
       "      <td>6097.128169</td>\n",
       "      <td>6706.759712</td>\n",
       "      <td>4070.352005</td>\n",
       "      <td>1730.354770</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2328.430968</td>\n",
       "      <td>10536.283689</td>\n",
       "      <td>2936.952418</td>\n",
       "      <td>3616.225195</td>\n",
       "      <td>3165.649901</td>\n",
       "      <td>9412.048018</td>\n",
       "      <td>4153.316209</td>\n",
       "      <td>4485.342977</td>\n",
       "      <td>2356.793875</td>\n",
       "      <td>2367.509649</td>\n",
       "      <td>...</td>\n",
       "      <td>2231.856228</td>\n",
       "      <td>5248.819202</td>\n",
       "      <td>3661.109612</td>\n",
       "      <td>4771.867713</td>\n",
       "      <td>2457.018149</td>\n",
       "      <td>6414.249686</td>\n",
       "      <td>7131.921433</td>\n",
       "      <td>5081.690930</td>\n",
       "      <td>2676.794673</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1354.269041</td>\n",
       "      <td>10152.716047</td>\n",
       "      <td>2277.135302</td>\n",
       "      <td>2934.142602</td>\n",
       "      <td>2554.509063</td>\n",
       "      <td>9108.994284</td>\n",
       "      <td>3612.459302</td>\n",
       "      <td>4105.696009</td>\n",
       "      <td>1405.134574</td>\n",
       "      <td>1446.620328</td>\n",
       "      <td>...</td>\n",
       "      <td>1208.402843</td>\n",
       "      <td>4808.928318</td>\n",
       "      <td>3373.489528</td>\n",
       "      <td>4334.749140</td>\n",
       "      <td>2218.127670</td>\n",
       "      <td>6038.226521</td>\n",
       "      <td>6798.884419</td>\n",
       "      <td>4849.692476</td>\n",
       "      <td>1934.536782</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1406.865361</td>\n",
       "      <td>10370.923579</td>\n",
       "      <td>2341.821311</td>\n",
       "      <td>3205.296657</td>\n",
       "      <td>2411.399094</td>\n",
       "      <td>9139.948002</td>\n",
       "      <td>3745.038834</td>\n",
       "      <td>4135.639397</td>\n",
       "      <td>1348.906112</td>\n",
       "      <td>1640.540348</td>\n",
       "      <td>...</td>\n",
       "      <td>1423.353515</td>\n",
       "      <td>4910.366385</td>\n",
       "      <td>3192.496217</td>\n",
       "      <td>4460.675460</td>\n",
       "      <td>2286.118544</td>\n",
       "      <td>6151.521941</td>\n",
       "      <td>6824.796435</td>\n",
       "      <td>4715.060002</td>\n",
       "      <td>1961.524960</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2991.281375</td>\n",
       "      <td>10717.269188</td>\n",
       "      <td>3417.343671</td>\n",
       "      <td>3931.443013</td>\n",
       "      <td>3767.556303</td>\n",
       "      <td>9515.787875</td>\n",
       "      <td>4533.260191</td>\n",
       "      <td>4862.391619</td>\n",
       "      <td>2734.903410</td>\n",
       "      <td>2951.016634</td>\n",
       "      <td>...</td>\n",
       "      <td>2822.275999</td>\n",
       "      <td>5552.325992</td>\n",
       "      <td>4071.903501</td>\n",
       "      <td>5003.978238</td>\n",
       "      <td>3379.531983</td>\n",
       "      <td>6641.413365</td>\n",
       "      <td>7179.568064</td>\n",
       "      <td>5248.549029</td>\n",
       "      <td>3222.049821</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   distanceto0   distanceto1  distanceto2  distanceto3  distanceto4  \\\n",
       "0  1158.757913  10308.004784  2184.890186  3570.769435  1764.062277   \n",
       "1  2328.430968  10536.283689  2936.952418  3616.225195  3165.649901   \n",
       "2  1354.269041  10152.716047  2277.135302  2934.142602  2554.509063   \n",
       "3  1406.865361  10370.923579  2341.821311  3205.296657  2411.399094   \n",
       "4  2991.281375  10717.269188  3417.343671  3931.443013  3767.556303   \n",
       "\n",
       "   distanceto5  distanceto6  distanceto7  distanceto8  distanceto9  ...  \\\n",
       "0  9178.431543  3627.118942  4014.283513  1053.936404  1398.246933  ...   \n",
       "1  9412.048018  4153.316209  4485.342977  2356.793875  2367.509649  ...   \n",
       "2  9108.994284  3612.459302  4105.696009  1405.134574  1446.620328  ...   \n",
       "3  9139.948002  3745.038834  4135.639397  1348.906112  1640.540348  ...   \n",
       "4  9515.787875  4533.260191  4862.391619  2734.903410  2951.016634  ...   \n",
       "\n",
       "   distanceto23  distanceto24  distanceto25  distanceto26  distanceto27  \\\n",
       "0   1064.633478   4828.255038   3091.622483   4353.631974   2134.944351   \n",
       "1   2231.856228   5248.819202   3661.109612   4771.867713   2457.018149   \n",
       "2   1208.402843   4808.928318   3373.489528   4334.749140   2218.127670   \n",
       "3   1423.353515   4910.366385   3192.496217   4460.675460   2286.118544   \n",
       "4   2822.275999   5552.325992   4071.903501   5003.978238   3379.531983   \n",
       "\n",
       "   distanceto28  distanceto29  distanceto30  distanceto31  cluster  \n",
       "0   6097.128169   6706.759712   4070.352005   1730.354770       10  \n",
       "1   6414.249686   7131.921433   5081.690930   2676.794673       23  \n",
       "2   6038.226521   6798.884419   4849.692476   1934.536782       17  \n",
       "3   6151.521941   6824.796435   4715.060002   1961.524960        8  \n",
       "4   6641.413365   7179.568064   5248.549029   3222.049821        8  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "af3256fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def svm_model(df, df_target):\n",
    "    for col in df_target.drop('id', axis=1).columns:\n",
    "        df_train, df_test = train_test_split(\n",
    "            df,\n",
    "            test_size=0.25\n",
    "        )\n",
    "        \n",
    "        svm = SVC()\n",
    "        svm_parameters_grid = {\n",
    "            'C': [1, 0.5],\n",
    "            'kernel': ['linear', 'sigmoid']\n",
    "        }\n",
    "        custom_cv = [(df_train.index.to_list(), df_test.index.to_list())]\n",
    "        \n",
    "        search_svm = GridSearchCV(\n",
    "            svm,\n",
    "            svm_parameters_grid,\n",
    "            return_train_score=True\n",
    "        )\n",
    "        train = df_train.merge(df_target[['id', col]], on='id', how='inner')\n",
    "        X, y = train.drop([col, 'id'], axis=1), train[col]\n",
    "        \n",
    "        search_svm.fit(X, y)\n",
    "        svm = SVC(**search_svm.best_params_)\n",
    "        svm.fit(X, y, verbose=False)\n",
    "        \n",
    "        scores_train.append(log_loss(y, svm.predict(X)))\n",
    "        test = df_test.merge(df_target[['id', col]], on='id', how='inner')\n",
    "        X, y = test.drop([col, 'id'], axis=1), test[col]\n",
    "        scores_test.append(log_loss(y, svm.predict(X)))\n",
    "    return (np.mean(scores_train), np.mean(scores_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1105b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score, test_score = svm_model(df_med, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c0340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Среднее качество на треине', train_score)\n",
    "print('Среднее качество на тесте', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c11f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def gaussian_kernel(distances, h=1):\n",
    "        return np.exp(- distances**2 / h**2)\n",
    "\n",
    "    \n",
    "def knn_model(df, df_target):\n",
    "    for col in df_target.drop('id', axis=1).columns:\n",
    "        df_train, df_test = train_test_split(\n",
    "            df,\n",
    "            test_size=0.25\n",
    "        )\n",
    "        parameters_grid = {\n",
    "        'n_neighbors': [5, 10, 20],\n",
    "        'weights': ['uniform', 'distance', gaussian_kernel],\n",
    "        'p': (2, 1),\n",
    "        }\n",
    "\n",
    "        custom_cv = [(df_train.index.to_list(), df_test.index.to_list())]\n",
    "\n",
    "        search_baseline = GridSearchCV(\n",
    "            KNeighborsClassifier(),\n",
    "            parameters_grid,\n",
    "            scoring=\"accuracy\",\n",
    "            cv=custom_cv,\n",
    "            verbose=10,\n",
    "            return_train_score=True\n",
    "        )\n",
    "        \n",
    "        train = df_train.merge(df_target[['id', col]], on='id', how='inner')\n",
    "        X, y = train.drop([col, 'id'], axis=1), train[col]\n",
    "        \n",
    "        search_baseline.fit(X, y)\n",
    "        knn = SVC(**search_baseline.best_params_)\n",
    "        knn.fit(X, y, verbose=False)\n",
    "        \n",
    "        scores_train.append(log_loss(y, knn.predict(X)))\n",
    "        test = df_test.merge(df_target[['id', col]], on='id', how='inner')\n",
    "        X, y = test.drop([col, 'id'], axis=1), test[col]\n",
    "        scores_test.append(log_loss(y, knn.predict(X)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score, test_score = knn_model(df_med, df_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
